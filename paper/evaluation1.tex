\section{Evaluation}
In our evaluation we compare the coverage of several JavaScript unit tests  
 with and without using our tool. Our intention is to demonstrate the improved path
coverage achieved when using our approach. First, we describe our evaluation 
methodology, followed by a detailed explanation of applying it to the DOMtris
running example. Finally, we provide results for number of other test cases and
analyze these results.

%Existing approaches to concolic testing JavaScript~\cite{kudzu, jalangi} focus on generating input parameters.  
%Yet the {\tt function checkRows()} does not take any input arguments.  Thus these approaches would likely execute the function by simply calling {\tt checkRows()}.
\subsection{Methodology}
For each unit test that we studied, we exercise it and measure coverage in the following 3 scenarios. We report the statement, branch, and path coverage for each scenario. 

\begin{enumerate}
\item {\em Without HTML: } For this scenario Jalangi is used to generate test cases which cover the input domain of tradition function argument inputs. However,
no HTML fixture is provided for the test case. This scenario corresponds to the
way developers might test JavaScript unit for which they know there is no
interaction with the DOM.
\item {\em Existing HTML: } This scenario extends the previous one by using Jalangi to provide function inputs but also using a single HTML fixture for all test cases of a function. We choose as the fixture the HTML which is initially constructed after the {\tt onLoad} event is handled by the application. This scenario
corresponds to a test setup that has low overhead for developers since they 
do not need to construct a dedicated HTML fixture which is ideally suited to each function. However, for the same reason, it could be expected this naive fixture setup would not yield comprehensive coverage.  
\item {\tool Generated HTML: } This scenario also uses Jalangi as in the first scenario, but here different HTML fixtures are provided as test case input based
on feedback from our \tool. The fixtures are generated according from our concolic driver to expand the executed coverage of the test case. Using our tool, for each of the original test cases generated by Jalangi a number of new cases are created with varying HTML fixtures. 
\end{enumerate}

%For each approach, we would follow the same methodology of loading and execution the function:

%\begin{compactitem}
%\item Open the target URL in the Web browser
%\item Load the HTML (except {\em Without HTML})
%\item Execute the target code
%\item Measure coverage
%\end{compactitem}

%Recalling from the Implementation section, the 4 steps above are identical to the initial 4 steps that our concolic driver would take in each iteration.  Additionally the concolic driver would take the executed paths as feedback and generate new HTML.  
%For {\tt function checkRows()}, we can simply call the function via {\tt checkRows()} because it does not take any input arguments.

\subsection{DOMtris Example}
Our evaluation starts with a detailed explanation in which we compare the different scenarios to the testing of the {\tt function checkRows()} in Sample Code \ref{dom0}.

\begin{figure}
\centerline{\scalebox{0.38}{\includegraphics[natwidth=1056,natheight=1100]{domtris.png}}}
\caption[DOMtris game field]{The DOMtris game field has 20 rows, thus {\tt field.children.length} is set to be 20 in our evaluation.}
\label{domtrisfield}
\end{figure}

\begin{figure}[h]
\centerline{
\begin{tabular}{*2l|*3c}
\hline
& & \multicolumn{3}{c}{Count (Number Of)} \\ 
App & Function & Statements & Branches & Paths \\ \hline
DOMtris & checkRows() & 6 & 4 & 41 \\ \hline
\end{tabular}
}
\caption{Number of Statements, Branches and Paths of function being evaluated.}
\label{paths}
\end{figure}
%\slopypar{


%}

\header{Counting Execution Paths.}
Figure \ref{paths} shows the number of statements, branches and paths that the function has.   
When counting the number of paths in the {\tt function checkRows()} in Sample Code \ref{dom0}, 
the original code does not pose an upper bound to the number of times the {\tt for} loop would get iterated because {\tt field.children.length} can be any value.
Therefore, we would set {\tt field.children.length} to a specific number for calculating the total number of possible execution paths in the function.
{\tt field} is set to have 20 children because the actual application always has 20 rows (Figure \ref{domtrisfield}). 
The following shows how the number of statements, branches and paths are counted for the {\tt function checkRows()}:
\begin{compactitem}
\item {\em Statements}: 6, {\tt line 2} to {\tt line 7}, inclusive.
\item {\em Branches}: 2 + 2. The {\tt for} loop has 2 branches: {\tt stay} and {\tt break}; plus the {\tt if} condition also has 2 branches: {\tt true} and {\tt false}. 
\item {\em Paths}: 20 ({\tt stay} branch in for loop) * 2 ({\tt true} and {\tt false} branches in {\tt if} statement) + 1 ({\tt break} branch).
\end{compactitem}

\begin{figure}[h]
\centerline{
\begin{tabular}{l|*3c}
\hline
& \multicolumn{3}{c}{Count (Number Of)} \\	
Approach & Statements & Branches & Paths \\ \hline
Optimal & 6 & 4 & 41 \\ \hline
{\em Without HTML} & 1 & 0 & 0 \\ 
{\em Existing HTML} & 5 & 3 & 1 \\ 
\tool & 6 & 4 & 41 \\ \hline
\end{tabular}
}
\caption{Statement, Branch and Path coverage of different approaches to testing the {\tt function checkRows()}. The Optimal approach is stated here to reference what perfect coverage would look like.}
\label{coverage}
\end{figure}

\header{Coverage Results.}
Figure \ref{coverage} shows the coverage results of different approaches to testing the {\tt function checkRows()}.  

The {\em Without HTML} approach cannot cover any statement because the first statement in the {\tt function checkRows()} is already a DOM operation requiring the existence of an element with ID {\tt "field"}.

The {\em Existing HTML} approach is able to cover 5 statements inclusively from {\tt line 2} to {\tt line 6} because the original HTML already has 20 rows inside {\tt field}.  
However the {\em Existing HTML} approach cannot cover the statement in {\tt line 7} because the rows do not have any children at the start of the game. 
{\em Existing HTML} is able to cover 3 of the 4 possible branches: both the {\tt stay} and {\tt break} branches in the {\tt for} loop, and the {\tt false} branch in the {\tt if} condition. 
Yet, the {\em Existing HTML} approach is able to cover only one path because going through a different path in {\tt function checkRows()} requires another unique DOM tree structure.  

\tool is able to cover all possible paths in {\tt function checkRows()} because we have set {\tt field.children.length} to be 20, 
and all the conditions (the {\tt for} loop and the {\tt if} condition) inside the function are all driven by DOM operations.  
In case when there are conditions that are driven by other data types, our solver would have to be extended to support these data types.    

\header{Discussion.}
In the specific example of {\tt function checkRows()}, using only the existing HTML is sufficient to achieve high statement coverage (5/6 or 83\%) and high branch coverage (3/4 or 75\%).  

Concolic testing often takes additional time, in our small example the DOM solver would take about 15 to 30 seconds to generate each additional HTML on a MacBook pro with a 2.0GHz quad core Intel i7 processor and 16GB RAM.
Thus whether concolic testing is worth it would depend on how much additional coverage the concolic approach would provide, and the benefits of having the additional coverage.  

While \tool covers only 1 additional statement ({\tt line 7}) and only 1 additional branch ({\tt true} branch of the {\tt if} condition) compared to {\em Existing HTML}, 
the additionally covered statement is responsible for updating the game's score, and scoring is a core functionality of DOMtris.  
Another benefit of \tool is that it covers all the different paths that generate the different permutations of increasing the score.  

Our current concolic driver is primitive in the sense that it exhaustively tries to cover all execution paths possible.  
In the future, it may be worth investigating if it is possible to design a smarter concolic driver that can give priority to execution paths that would yield the highest marginal benefit of additional coverage: 
e.g. highest additional branch coverage, the most diverse permutation of increasing the score, etc.  
That way the tester can exercise concolic testing partially, combine concolic testing with other less expensive testing methods (e.g. ~\cite{feedbackConcolic, hybridconcolic}), and still achieve certain desired outcomes without incurring the full costs associated with complete concolic execution.  
Thus having a prioritized concolic engine would give the tester greater control to manage the costs and benefits of the testing life cycle.  

\subsection{Other Applications}

\begin{figure*}[t]
\centerline{
\begin{tabular}{|*2l|*3c|*3c|*3c|}
\hline
& & \multicolumn{3}{|c|}{Statements} & \multicolumn{3}{|c|}{Branches} & \multicolumn{3}{|c|}{Paths}\\ 
App & \# func. & None & Static & Conc. & None & Static & Conc. & None & Static & Conc. \\ \hline
DOMtris &  &  &  & & & & & & &\\ \hline
Mancala &  &  &  & & & & & & &  \\ \hline
Ghostbusters &  &  &  & & & & & & &  \\ \hline
etc... &  &  &  & & & & & & & \\ \hline
\end{tabular}
}
\caption{Average number of Statements, Branches and Paths for functions being evaluated for a number of applications. For each metric, a column presents the results Without HTML (None), With existing HTML (Static), and using our tool (Conc.).} 
\label{paths}
\end{figure*}

% yahoo
% Tinysort
%  http://tinysort.sjeiti.com/
% Zen Coding
%  http://zen.sjeiti.com/
% DOMtris
%  http://www.ugrad.cs.ubc.ca/~k5r4/nbpAFZyrx5o/tracing/domtris/domtris.html
% Tudu
%  http://app.rasc.ch/tudu/welcome.action
% Knockout:
%  http://knockoutjs.com/examples/ 
% JQuery Widget: 
%  http://jqueryui.com/demos/
%  http://wijmo.com/widgets/
% Tizen
%   https://developer.tizen.org/downloads/sample-web-applications
%			mancala
