\section{Future Work \& Conclusion}
This paper is the first in the series of our study on data scientists prototyping model-based recommender systems.  
We explored the convex-optimization perspective of the problem: we propose Stochastic Average Gradient as a viable alternative to Full Deterministic gradient and Stochastic gradient.  
By taking advantage of \emph{SAG}'s fast convergence rate and low iteration cost, we aim to enable data-scientists run more experiments and produce high quality results with less time.  
In theory, we proved that our extension and adaptation of \emph{SAG} preserves the fast convergence rate as the original \emph{SAG}.  
Furthermore, \tool has asymptotic time complexity as efficient as gradient methods with the lowest itreation cost, and asymptotic space complexity as compact as any memory-less gradient methods.  
In practice, through extensive evaluation we demonstrated that, even without any fine-tuning or optimization of the implementation, 
\tool still outperforms both full deterministic gradient and stochastic gradient in terms of reaching the best quality optimization within the same amount of time.  
Following up, we provided evidence that full deterministic gradient and stochastic gradient would take much longer to reach a quality of optimization similar to \tool.

Currently we are extending \tool in two directions.  Both directions relate to running an iteration of full deterministic gradient in \tool.
First, we are investigating if it is beneficial to run an iteration of full deterministic gradient more often.  
In our experiments, we observed that both \emph{SG} and \emph{SAG} may converge early; the optimization may get stuck at a local sub-optimum for a long number of iterations.  
Thus we are exploring if an iteration of full deterministic gradient would get the optimization back on track in case \tool gets stuck.
Secondly, we aim to investigate how well \tool would perform in the production environment, and in distributed systems potentially running in parallel, because running full deterministic gradient even once can be prohibitive for full-scale datasets with millions to billions of non-zero entries.

% the recommender perspective 
In the future, we also aim to complete our ongoing work on the metrics perspective and on the software engineering perspective.  
Given a dataset, the quality of a recommender system is often evaluated in various metrics: 
e.g. precision, recall, area under curve, reciprocal rank, NDCG, and variants of the above such as top-K precision and top-K hit rate.
% what is NDCG?
Many papers in the literature claim their objective function is better by illustrating that their objective function performs in some of these metrics better than other objective functions.  
Therefore, in the metrics perspective, we are exploring and investigating which factors are more relevant and important towards scoring high in the various metrics: 
is it the objective function, the method for convex-optimization such as \emph{SAG}, other fine-tuning mechanisms such as bootstrapping, 
or the hyper-parameters that we use in convex-optimization.  All of these factors can be dataset-specific.  
Indeed, our inherent assumption in this paper is that a better quality optimization yields better recommender systems. 
In the future, we would like to explore if there are other factors that are more worthwhile than a fast convergence rate or a low iteration cost towards better recommender systems.  

% the software engineering perspective 
In the software engineering perspective, we study how to increase the productivity of data scientists.  
At this point, we are designing and developing a \emph{mix-n-match} or \emph{plug-n-play} framework that enables data scientists in a least effort way, 
to very rapidly prototype and experiment many different combinations of objective functions, datasets, gradient methods, hyper parameters and evaluation metrics.  
